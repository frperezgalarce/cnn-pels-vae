{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b474a645-e5fb-4f0d-a0c6-7a33b8057fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "new_directory = '/home/franciscoperez/Documents/GitHub/CNN-PELSVAE2/cnn-pels-vae/'\n",
    "os.chdir(new_directory)\n",
    "\n",
    "import yaml\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import src.utils as utils\n",
    "from typing import Union, Tuple, Optional, Any, Dict, List\n",
    "import src.gmm.modifiedgmm as mgmm\n",
    "from src.utils import load_pp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b1028926-e324-4303-bda0-09f18fc04604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/franciscoperez/Documents/GitHub/CNN-PELSVAE2/cnn-pels-vae/models/',\n",
       " '/home/franciscoperez/Documents/GitHub/CNN-PELSVAE2/cnn-pels-vae/data')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('src/paths.yaml', 'r') as file:\n",
    "    file = yaml.safe_load(file)\n",
    "PATHS = file['paths']\n",
    "PATH_MODELS =PATHS['PATH_MODELS']\n",
    "PATH_DATA = PATHS['PATH_DATA_FOLDER']\n",
    "\n",
    "PATH_MODELS, PATH_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f003bb1-8eee-4eaf-a123-f1c975f2cc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in Label Encoder: ['ACEP' 'CEP' 'DSCT' 'ECL' 'ELL' 'LPV' 'RRLYR' 'T2CEP']\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_MODELS+'label_encoder_vae.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "print(\"Classes in Label Encoder:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d3f8f45-7dee-41d1-93c3-f6e12099a1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('src/nn_config.yaml', 'r') as file:\n",
    "    nn_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9531ccb4-d882-4845-b943-318bc0f1a685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('src/gmm/priors.yaml', 'r') as file:\n",
    "    mean_prior_dict = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6890f9f5-2d3f-4325-8a1c-e5dc9f69e87d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vae model: 16f09v2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Period', 'teff_val', '[Fe/H]_J95', 'abs_Gmag', 'radius_val', 'logg']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('src/regressor.yaml', 'r') as file:\n",
    "    config_file: Dict[str, Any] = yaml.safe_load(file)\n",
    "vae_model: str =   config_file['model_parameters']['ID']  \n",
    "print('Using vae model: '+ vae_model)\n",
    "PP_list = load_pp_list(vae_model)\n",
    "PP_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a69dd5f-c758-47ea-9f75-644236bd8900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_example=False\n",
    "b=1.0\n",
    "wandb_active=False\n",
    "samples_dict = None\n",
    "lb = []\n",
    "n_samples = 8\n",
    "PP = PP_list\n",
    "priors = True\n",
    "sinthetic_samples_by_class = 8\n",
    "dict_priorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0f21907a-c81d-4b2f-9866-a9088af0e4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Any, Dict, List\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import src.utils as utils\n",
    "import src.gmm.modifiedgmm as mgmm\n",
    "import src.sampler.fit_regressor as reg\n",
    "import matplotlib.pyplot as plt\n",
    "from src.sampler.LightCurveRandomSampler import LightCurveRandomSampler\n",
    "\n",
    "gpu: bool = True \n",
    "with open('src/nn_config.yaml', 'r') as file:\n",
    "    nn_config = yaml.safe_load(file)\n",
    "\n",
    "class SyntheticDataBatcher:\n",
    "    def __init__(self, config_file_path: str = 'src/regressor.yaml', \n",
    "                 nn_config_path: str = 'src/nn_config.yaml', paths: str = 'src/paths.yaml', PP=[], vae_model=None, \n",
    "                 n_samples=16, seq_length = 100, batch_size=128, prior=False):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.config_file = self.load_yaml(config_file_path)\n",
    "        self.nn_config = self.load_yaml(nn_config_path)\n",
    "        self.path = self.load_yaml(paths)['paths']\n",
    "        self.mean_prior_dict = self.load_yaml(self.path['PATH_PRIOS'])  # to be filled in later\n",
    "        self.priors = prior\n",
    "        self.PP = PP\n",
    "        self.vae_model = vae_model\n",
    "        self.n_samples = n_samples\n",
    "        self.seq_length = seq_length\n",
    "        self.delta_max = 100\n",
    "        self.CLASSES = ['ACEP','CEP', 'DSCT', 'ECL',  'ELL', 'LPV',  'RRLYR', 'T2CEP']\n",
    "        self.batch_size = batch_size\n",
    "        self.x_array = None\n",
    "        self.y_array = None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_yaml(path: str) -> Dict[str, Any]:\n",
    "        with open(path, 'r') as file:\n",
    "            return yaml.safe_load(file)\n",
    "\n",
    "    def construct_model_name(self, star_class: str, base_path: str = 'PATH_MODELS'):\n",
    "        \"\"\"Construct a model name given parameters.\"\"\"\n",
    "        file_name = f\"{base_path}bgm_model_{str(star_class)}_priors_{self.priors}_PP_{len(self.PP)}.pkl\"\n",
    "        return file_name\n",
    "\n",
    "    @staticmethod\n",
    "    def count_subclasses(star_type_data: Dict[str, Any]) -> int:\n",
    "        excluded_keys = ['CompleteName', 'min_period', 'max_period']\n",
    "        return len([key for key in star_type_data.keys() if key not in excluded_keys])\n",
    "\n",
    "    def process_in_batches(self, model, mu_, times, onehot, phy, batch_size):\n",
    "        # Split tensors into smaller batches\n",
    "        total_samples = mu_.size(0)\n",
    "        n_batches = (total_samples + batch_size - 1) // batch_size\n",
    "\n",
    "        results = []\n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, total_samples)\n",
    "\n",
    "            mu_batch = mu_[start_idx:end_idx]\n",
    "            times_batch = times[start_idx:end_idx]\n",
    "            onehot_batch = onehot[start_idx:end_idx]\n",
    "            phy_batch = phy[start_idx:end_idx]\n",
    "\n",
    "            xhat_mu_batch = model.decoder(mu_batch, times_batch, label=onehot_batch, phy=phy_batch)\n",
    "            results.append(xhat_mu_batch)\n",
    "            del xhat_mu_batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Concatenate results from all batches\n",
    "        xhat_mu = torch.cat(results, dim=0)\n",
    "        return xhat_mu\n",
    "\n",
    "    def attempt_sample_load(self, model_name: str, sampler: 'YourSamplerType', n_samples=nn_config['training']['sinthetic_samples_by_class']) -> Tuple[Union[np.ndarray, None], bool]:\n",
    "        try:\n",
    "            samples = sampler.modify_and_sample(model_name, n_samples=n_samples, \n",
    "                                                mode= nn_config['sampling']['mode'])\n",
    "            return samples, True\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to load samples from model {model_name}. Error: {str(e)}\")\n",
    "\n",
    "    def create_time_sequences(self, lb, period, based_on_real_lc = True):\n",
    "        np.set_printoptions(suppress=True)\n",
    "        print(lb)\n",
    "        print(period)\n",
    "        if based_on_real_lc:\n",
    "            times, original_sequences =  utils.get_only_time_sequence(n=1, star_class=lb, \n",
    "                                                                     period = period, factor1=0.8, \n",
    "                                                                     factor2= 1.2)\n",
    "            times = np.array(times) \n",
    "            original_sequences = np.array(original_sequences) \n",
    "            times = torch.from_numpy(times).to(self.device)\n",
    "            times = times.to(dtype=torch.float32)\n",
    "        else: \n",
    "            times = [i/600 for i in range(600)]\n",
    "            times = np.tile(times, (self.n_samples*len(list(self.nn_config['data']['classes'])), 1))\n",
    "            times = np.array(times)  \n",
    "            times = torch.from_numpy(times).to(self.device)\n",
    "            times = times.to(dtype=torch.float32)\n",
    "            original_sequences = None #TODO\n",
    "        \n",
    "        return times, original_sequences\n",
    "\n",
    "    def create_synthetic_batch(self, plot_example=False, b=1.0, wandb_active=False, samples_dict = None):\n",
    "        print(self.path)\n",
    "        PATH_MODELS = self.path['PATH_MODELS']\n",
    "        PATH_DATA = self.path['PATH_DATA_FOLDER']\n",
    "        lb = []\n",
    "\n",
    "        with open(PATH_MODELS+'label_encoder_vae.pkl', 'rb') as f:\n",
    "            label_encoder = pickle.load(f)\n",
    "\n",
    "        for star_class in list(self.nn_config['data']['classes']):\n",
    "            torch.cuda.empty_cache()\n",
    "            print('------- sampling ' +star_class+'---------')\n",
    "            \n",
    "            if samples_dict==None:\n",
    "                n_samples = self.n_samples\n",
    "                lb += [star_class] * self.n_samples\n",
    "            else: \n",
    "                n_samples = int(samples_dict[star_class])\n",
    "                lb += [star_class] * n_samples\n",
    "            \n",
    "            print(samples_dict)\n",
    "\n",
    "\n",
    "            integer_encoded = label_encoder.transform(lb)\n",
    "            n_values = len(label_encoder.classes_)\n",
    "            onehot = np.eye(n_values)[integer_encoded]\n",
    "\n",
    "            encoded_labels, _ = utils.transform_to_consecutive(integer_encoded, label_encoder)\n",
    "            n_values = len(np.unique(encoded_labels))\n",
    "            onehot_to_train = np.eye(n_values)[encoded_labels]\n",
    "\n",
    "            components = self.count_subclasses(self.mean_prior_dict['StarTypes'][star_class])\n",
    "\n",
    "            print(star_class +' includes '+ str(components) +' components ')\n",
    "\n",
    "            sampler: mgmm.ModifiedGaussianSampler = mgmm.ModifiedGaussianSampler(b=b, \n",
    "                                                                                components=components, \n",
    "                                                                                features=self.PP)\n",
    "            model_name = self.construct_model_name(star_class, PATH_MODELS)\n",
    "            samples, error = self.attempt_sample_load(model_name, sampler, n_samples=n_samples)\n",
    "            \n",
    "            # If we have priors and failed to load the model, try with priors=False\n",
    "            if self.priors and samples is None:\n",
    "                model_name = self.construct_model_name(star_class, PATH_MODELS)\n",
    "                samples, error = self.attempt_sample_load(model_name, sampler, n_samples=n_samples)\n",
    "            \n",
    "            # If still not loaded, raise an error\n",
    "            if samples is None:\n",
    "                raise ValueError(\"The model can't be loaded.\" + str(error))\n",
    "\n",
    "            if 'all_classes_samples' in locals() and all_classes_samples is not None: \n",
    "                all_classes_samples = np.vstack((all_classes_samples, samples))\n",
    "            else: \n",
    "                all_classes_samples = samples\n",
    "                print(all_classes_samples.shape)\n",
    "\n",
    "        print('cuda: ', torch.cuda.is_available())\n",
    "        print('model: ', self.vae_model)\n",
    "\n",
    "\n",
    "        columns = ['Period', 'teff_val', '[Fe/H]_J95', 'abs_Gmag', 'radius_val', 'logg']\n",
    "        index_period = columns.index('Period')\n",
    "        mu_ = reg.process_regressors(self.config_file, phys2=columns, samples= all_classes_samples, \n",
    "                                            from_vae=False, train_rf=False)\n",
    "\n",
    "\n",
    "        # Directly convert to tensors and move to the GPU\n",
    "        mu_ = torch.tensor(mu_, device=self.device)\n",
    "        onehot = torch.tensor(onehot, device=self.device)\n",
    "        lb = np.array(lb)  \n",
    "        pp = torch.tensor(all_classes_samples, device=self.device)\n",
    "\n",
    "        # Clear GPU cache\n",
    "        vae, _ = utils.load_model_list(ID=self.vae_model, device=self.device)\n",
    "        times, original_sequences = self.create_time_sequences(lb, all_classes_samples[:,index_period])\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        xhat_mu = self.process_in_batches(vae, mu_, times, onehot, pp, 1)\n",
    "        xhat_mu = torch.cat([times.unsqueeze(-1), xhat_mu], dim=-1).cpu().detach().numpy()\n",
    "\n",
    "        #TODO: filter here light curves\n",
    "\n",
    "        indices = np.random.choice(xhat_mu.shape[0], 24, replace=False)\n",
    "        sampled_arrays = xhat_mu[indices, :, :]\n",
    "\n",
    "        utils.plot_wall_lcs_sampling(sampled_arrays, sampled_arrays,  cls=lb[indices],  column_to_sensivity=index_period,\n",
    "                                to_title = pp[indices], sensivity = 'Period', all_columns=columns, save=False, wandb_active=wandb_active) \n",
    "\n",
    "        lc_reverted = utils.revert_light_curve(pp[:,index_period], xhat_mu, original_sequences, classes = lb)\n",
    "\n",
    "        if plot_example:\n",
    "            plt.figure()\n",
    "            plt.scatter(lc_reverted[0][1], lc_reverted[0][0])\n",
    "            plt.show()\n",
    "\n",
    "        mean_value = np.nanmean(lc_reverted)\n",
    "        lc_reverted[np.isnan(lc_reverted)] = mean_value\n",
    "        oversampling = True\n",
    "\n",
    "        if oversampling: \n",
    "            sampler = LightCurveRandomSampler(lc_reverted, onehot_to_train, self.seq_length, 12)\n",
    "            lc_reverted, onehot_to_train = sampler.sample()\n",
    "        else:\n",
    "            lc_reverted = lc_reverted[:, :, :self.seq_length]\n",
    "\n",
    "        lc_reverted = np.diff(lc_reverted, axis=-1)\n",
    "        mean_value = np.nanmean(lc_reverted)\n",
    "        lc_reverted[(lc_reverted)> self.delta_max] = mean_value\n",
    "\n",
    "        if plot_example:\n",
    "            plt.figure()\n",
    "            plt.scatter(lc_reverted[0][1], lc_reverted[0][0])\n",
    "            plt.show()\n",
    "\n",
    "        if np.sum(np.isnan(lc_reverted)) > 0:\n",
    "            print(f\"Number of NaN values detected: {np.sum(np.isnan(lc_reverted))}\")\n",
    "            raise ValueError(\"NaN values detected in lc_reverted array\")\n",
    "\n",
    "        utils.save_arrays_to_folder(lc_reverted, onehot_to_train , PATH_DATA)\n",
    "\n",
    "        numpy_array_x = np.load(PATH_DATA+'/x_batch_pelsvae.npy', allow_pickle=True)\n",
    "        numpy_array_y = np.load(PATH_DATA+'/y_batch_pelsvae.npy', allow_pickle=True)\n",
    "\n",
    "        self.x_array = numpy_array_x\n",
    "        self.y_array = numpy_array_y \n",
    "        \n",
    "        if plot_example:\n",
    "            plt.figure()\n",
    "            plt.scatter(numpy_array_x[0][0], numpy_array_x[0][1])\n",
    "            plt.show()\n",
    "\n",
    "        synth_data = utils.move_data_to_device((numpy_array_x, numpy_array_y), self.device)\n",
    "        synthetic_dataset = TensorDataset(*synth_data)\n",
    "        synthetic_dataloader = DataLoader(synthetic_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return synthetic_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73908a2e-e439-4c3a-bc0b-c9ba768abee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batcher = SyntheticDataBatcher(PP = PP, vae_model=vae_model, n_samples=sinthetic_samples_by_class, \n",
    "                                    seq_length = 300, prior=priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e17599-f486-42db-8c61-89a45bd473c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PATH_PRIOS': 'src/gmm/priors.yaml', 'PATH_PP': '/home/franciscoperez/Documents/GitHub/CNN-PELSVAE2/cnn-pels-vae/data/metadata_updated_0823.csv', 'PATH_LIGHT_CURVES_OGLE': '/home/franciscoperez/Desktop/Code/FATS/LCsOGLE/data/', 'PATH_FEATURES_TRAIN': '/home/franciscoperez/Documents/GitHub/data/BIASEDFATS/Train_rrlyr-1.csv', 'PATH_FEATURES_TEST': '/home/franciscoperez/Documents/GitHub/data/BIASEDFATS/Test_rrlyr-1.csv', 'PATH_NUMPY_DATA_X_TRAIN': 'data/train_np_array.npy', 'PATH_NUMPY_DATA_X_TEST': 'data/test_np_array.npy', 'PATH_NUMPY_DATA_Y_TRAIN': 'data/train_np_array_y.npy', 'PATH_NUMPY_DATA_Y_TEST': 'data/test_np_array_y.npy', 'PATH_SUBCLASSES': '/home/franciscoperez/Documents/GitHub/vsbms_multiple_classes/bayesianMLP/src/data/all_subclasses', 'PATH_DATA_FOLDER': '/home/franciscoperez/Documents/GitHub/CNN-PELSVAE2/cnn-pels-vae/data', 'PATH_COLAB_ROOT': '/content/drive/My Drive/Colab_Notebooks/data', 'PATH_EXALEARN_ROOT': '/home/user/data', 'PATH_MODELS': '/home/franciscoperez/Documents/GitHub/CNN-PELSVAE2/cnn-pels-vae/models/', 'PATH_FIGURES': '/home/franciscoperez/Documents/GitHub/CNN-PELSVAE2/cnn-pels-vae/figures/', 'PATH_ZIP_GAIA': '/time_series/real/OGLE3_lcs_I_meta_snr5_augmented_folded_trim600.npy.gz'}\n",
      "------- sampling CEP---------\n",
      "None\n",
      "CEP includes 4 components \n",
      "8\n",
      "loading model:  /home/franciscoperez/Documents/GitHub/CNN-PELSVAE2/cnn-pels-vae/models/bgm_model_CEP_priors_True_PP_6.pkl\n",
      "BayesianGaussianMixture(max_iter=5000, n_components=4, random_state=42)\n",
      "Model loaded:  BayesianGaussianMixture(max_iter=5000, n_components=4, random_state=42)\n",
      "[[    1.7258  5905.4216    -2.2795     5.0023     0.8892     4.4646]\n",
      " [    2.1051 11508.8719    -0.6241     1.0729     2.1411     4.1986]\n",
      " [    3.0139  6192.288     -0.7515     2.8386     2.1284     3.8449]\n",
      " [    6.975   5745.8951    -0.9112     1.5514     5.0827     3.3044]]\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_loader = batcher.create_synthetic_batch(b=b, wandb_active=wandb_active, samples_dict = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946db542-a4c2-49c3-afe6-72e74ed660dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
