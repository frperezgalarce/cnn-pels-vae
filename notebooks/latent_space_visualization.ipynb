{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T19:06:18.398274Z",
     "start_time": "2019-09-20T19:06:15.299296Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob, re, sys\n",
    "import socket\n",
    "import torch\n",
    "#import wandb\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "#import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.vae_models import *\n",
    "from src.datasets import Astro_lightcurves\n",
    "from src.utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "main_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "save_plots = False\n",
    "save_tables = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "data_path = \"/home/franciscoperez/Documents/GitHub/CNN-PELSVAE/src/PELS-VAE/data/time_series/real/OGLE3_lcs_I_meta_snr5_augmented_folded_trim600.npy.gz\"\n",
    "with gzip.open(data_path, 'rb') as f:\n",
    "    test = np.load(f, allow_pickle=True)\n",
    "    test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to interpret file '/home/franciscoperez/Documents/GitHub/CNN-PELSVAE/src/PELS-VAE/data/time_series/real/OGLE3_lcs_I_meta_snr5_augmented_folded_trim600.npy.gz' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x1f'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1b07da980857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 raise IOError(\n\u001b[0;32m--> 451\u001b[0;31m                     \"Failed to interpret file %s as a pickle\" % repr(file)) from e\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Failed to interpret file '/home/franciscoperez/Documents/GitHub/CNN-PELSVAE/src/PELS-VAE/data/time_series/real/OGLE3_lcs_I_meta_snr5_augmented_folded_trim600.npy.gz' as a pickle"
     ]
    }
   ],
   "source": [
    "np.load(data_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 'b68z1hwo'\n",
    "gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T19:06:18.481120Z",
     "start_time": "2019-09-20T19:06:18.402129Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('%s/wandb/run--%s/VAE_model_None.pt' % \n",
    "                      (main_path, ID)):\n",
    "    print('Downloading files from Weight & Biases')\n",
    "    \n",
    "    api = wandb.Api()\n",
    "    run = api.run('jorgemarpa/Phy-VAE/%s' % (ID))\n",
    "    run.file('VAE_model_None.pt').download(replace=True, \n",
    "                                           root='%s/wandb/run--%s/' % \n",
    "                                           (main_path, ID))\n",
    "    run.file('config.yaml').download(replace=True, \n",
    "                                     root='%s/wandb/run--%s/' % \n",
    "                                     (main_path, ID))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model variables into VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T21:27:04.387324Z",
     "start_time": "2019-09-20T21:27:03.911070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from... \n",
      " /home/franciscoperez/Documents/GitHub/CNN-PELSVAE/src/PELS-VAE/wandb/run--b68z1hwo/VAE_model_None.pt\n",
      "Is model in cuda?  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'architecture': 'tcn',\n",
       " 'batch_size': 128,\n",
       " 'beta_vae': '0.75',\n",
       " 'classes': 'all',\n",
       " 'data': 'OGLE3',\n",
       " 'dropout': 0.2,\n",
       " 'epochs': 150,\n",
       " 'feed_pp': 'F',\n",
       " 'hidden_size': 48,\n",
       " 'kernel_size': 5,\n",
       " 'label_dim': 8,\n",
       " 'latent_dim': 4,\n",
       " 'latent_mode': 'repeat',\n",
       " 'learning_rate': 0.001,\n",
       " 'learning_rate_scheduler': 'cos',\n",
       " 'n_feats': 3,\n",
       " 'n_train_params': 300897,\n",
       " 'num_layers': 9,\n",
       " 'phys_params': 'PTA',\n",
       " 'physics_dim': 0,\n",
       " 'sequence_lenght': 600,\n",
       " 'transpose': False,\n",
       " 'normed': True,\n",
       " 'folded': True,\n",
       " 'date': '',\n",
       " 'ID': 'b68z1hwo'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae, config = load_model_list(ID=ID)\n",
    "config['phys_params'] = 'PTA'\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'karimsala6s'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T21:27:09.579379Z",
     "start_time": "2019-09-20T21:27:05.272292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from:\n",
      " /home/franciscoperez/Documents/GitHub/CNN-PELSVAE/src/PELS-VAE/data/time_series/real/OGLE3_lcs_I_meta_snr5_augmented_folded_trim600.npy.gz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__cinit__() takes at least 2 positional arguments (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4785ac89a897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                             \u001b[0mmachine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgethostname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                             \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence_lenght'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                             phy_params=config['phys_params'])\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/CNN-PELSVAE/src/PELS-VAE/src/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, survey, band, use_time, use_err, norm, folded, machine, seq_len, phy_params, subsample)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading from:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lcs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 441\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;31m# Friendlier error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/_libs/internals.pyx\u001b[0m in \u001b[0;36mpandas._libs.internals.BlockManager.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __cinit__() takes at least 2 positional arguments (0 given)"
     ]
    }
   ],
   "source": [
    "dataset = Astro_lightcurves(survey=config['data'],\n",
    "                            band='I' if config['data'] else 'B',\n",
    "                            use_time=True,\n",
    "                            use_err=True,\n",
    "                            norm=config['normed'],\n",
    "                            folded=config['folded'],\n",
    "                            machine=socket.gethostname(),\n",
    "                            seq_len=config['sequence_lenght'],\n",
    "                            phy_params=config['phys_params'])\n",
    "\n",
    "print('here')\n",
    "\n",
    "if config['classes'].split('_')[0] == 'drop':\n",
    "    dataset.drop_class(config['classes'].split('_')[1])\n",
    "elif config['classes'].split('_')[0] == 'only':\n",
    "    dataset.only_class(config['classes'].split('_')[1])\n",
    "print('Using physical parameters: ', dataset.phy_names)\n",
    "dataset.remove_nan()\n",
    "print(dataset.class_value_counts())\n",
    "print('Total: ', len(dataset))\n",
    "num_cls = dataset.labels_onehot.shape[1]\n",
    "\n",
    "dataloader, _ = dataset.get_dataloader(batch_size=100, \n",
    "                                       test_split=0., shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T21:27:10.329593Z",
     "start_time": "2019-09-20T21:27:09.583184Z"
    }
   },
   "outputs": [],
   "source": [
    "mu, std = evaluate_encoder(vae, dataloader, config, \n",
    "                           n_classes=num_cls, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot LC reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "meta_aux = dataset.meta.reset_index()\n",
    "for i, cls in enumerate(dataset.label_onehot_enc.categories_[0]):\n",
    "    aux = meta_aux.query('Type == \"%s\"' % (cls)).sample(3)\n",
    "    examples.append(aux)\n",
    "examples = pd.concat(examples, axis=0)\n",
    "print(examples.index)\n",
    "\n",
    "\n",
    "data, lb, onehot, pp = dataset[examples.index]\n",
    "data = torch.from_numpy(data).to(device)\n",
    "onehot = torch.from_numpy(onehot).to(device)\n",
    "pp = torch.from_numpy(pp).to(device)\n",
    "\n",
    "if config['label_dim'] > 0 and config['physics_dim'] > 0:\n",
    "    xhat_z, mu_, logvar_, z_ = vae(data, label=onehot, phy=pp)\n",
    "    xhat_mu = vae.decoder(mu_, data[:,:,0], label=onehot, phy=pp)\n",
    "elif config['label_dim'] > 0 and config['physics_dim'] == 0:\n",
    "    xhat_z, mu_, logvar_, z_ = vae(data, label=onehot)\n",
    "    xhat_mu = vae.decoder(mu_, data[:,:,0], label=onehot)\n",
    "elif config['label_dim'] == 0:\n",
    "    xhat_z, mu_, logvar_, z_ = vae(data)\n",
    "    xhat_mu = vae.decoder(mu_, data[:,:,0])\n",
    "else:\n",
    "    print('Check conditional dimension...')\n",
    "\n",
    "xhat_z = torch.cat([data[:,:,0].unsqueeze(-1), xhat_z], dim=-1).detach().numpy()\n",
    "xhat_mu = torch.cat([data[:,:,0].unsqueeze(-1), xhat_mu], dim=-1).detach().numpy()\n",
    "data = data.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wall_lcs(xhat_mu, data, cls=lb, save=save_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint distributions of latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sb.PairGrid(mu, \n",
    "                hue='class', hue_order=sorted(set(mu.loc[:,'class'].values)),\n",
    "               corner=False, despine=True, palette='Dark2_r')\n",
    "g = g.map_diag(plt.hist, histtype='step', lw=1.5)\n",
    "g = g.map_offdiag(plt.scatter, marker='.', s=20, alpha=.5, edgecolors='none')\n",
    "for i, j in zip(*np.triu_indices_from(g.axes, 1)):\n",
    "    g.axes[i, j].set_visible(False)\n",
    "g = g.add_legend(loc='upper center', fontsize=20, title='', \n",
    "                 markerscale=4, ncol=2)    \n",
    "for ax in g.axes.flat:\n",
    "    # This only works for the left ylabels\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize='x-large')\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize='x-large')\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig('%s/imgs/z_pairplot_%s.pdf' % (path,ID), \n",
    "            format='pdf', bbox_inches='tight')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE projection to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.shape, dataset.meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T21:29:10.058144Z",
     "start_time": "2019-09-20T21:27:17.136262Z"
    }
   },
   "outputs": [],
   "source": [
    "rnd_idx = np.random.choice(mu.index.values, replace=False, size=20000)\n",
    "mu_to_tsne = mu.loc[rnd_idx]\n",
    "meta_to_tsne = dataset.meta.loc[rnd_idx]\n",
    "print(meta_to_tsne.Type.value_counts())\n",
    "\n",
    "#for perplex in [2,5,8,10,15,20,25,30,40,50,100]:\n",
    "tsne = TSNE(n_components=2, perplexity=40, \n",
    "            random_state=10, verbose=0)\n",
    "mu_embed = tsne.fit_transform(mu_to_tsne.iloc[:,:-1].values)\n",
    "print('Embeding shape: ', mu_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-20T21:29:13.866972Z",
     "start_time": "2019-09-20T21:29:10.063304Z"
    }
   },
   "outputs": [],
   "source": [
    "scatter_hue(mu_embed[:,0], mu_embed[:,1], \n",
    "            mu_to_tsne.loc[:,'class'].values,\n",
    "            disc=True)\n",
    "scatter_hue(mu_embed[:,0], mu_embed[:,1], \n",
    "            np.log10(meta_to_tsne.loc[:,'teff_val'].values),\n",
    "            disc=False, c_label=r'$T_{eff}$')\n",
    "scatter_hue(mu_embed[:,0], mu_embed[:,1], \n",
    "            meta_to_tsne.loc[:,'bp_rp'].values,\n",
    "            disc=False, c_label='bp-rp')\n",
    "scatter_hue(mu_embed[:,0], mu_embed[:,1], \n",
    "            meta_to_tsne.loc[:,'abs_Gmag'].values,\n",
    "            disc=False, c_label=r'$M_g$')\n",
    "scatter_hue(mu_embed[:,0], mu_embed[:,1], \n",
    "            np.log10(meta_to_tsne.loc[:,'Period'].values),\n",
    "            disc=False, c_label='log(P)')\n",
    "scatter_hue(mu_embed[:,0], mu_embed[:,1], \n",
    "            meta_to_tsne.loc[:,'[Fe/H]_J95'].values,\n",
    "            disc=False, c_label='[Fe/H]_J95')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP projection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "metrics = ['euclidean',\n",
    "'manhattan',\n",
    "'chebyshev',\n",
    "'minkowski',\n",
    "'seuclidean',\n",
    "'cosine',\n",
    "'correlation',\n",
    "'hamming',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umapper = umap.UMAP(n_neighbors=100, min_dist=0.05, \n",
    "                    n_components=2, metric='euclidean')\n",
    "embedding = umapper.fit_transform(mu_to_tsne.iloc[:,:-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_hue(embedding[:,0], embedding[:,1], \n",
    "            meta_to_tsne.loc[:,'Type'].values,\n",
    "            disc=True)\n",
    "scatter_hue(embedding[:,0], embedding[:,1], \n",
    "            meta_to_tsne.loc[:,'bp_rp'].values,\n",
    "            disc=False, c_label='bp-rp')\n",
    "scatter_hue(embedding[:,0], embedding[:,1], \n",
    "            meta_to_tsne.loc[:,'abs_Gmag'].values,\n",
    "            disc=False, c_label=r'$M_g$')\n",
    "scatter_hue(embedding[:,0], embedding[:,1], \n",
    "            np.log10(meta_to_tsne.loc[:,'Period'].values),\n",
    "            disc=False, c_label='log(P)')\n",
    "scatter_hue(embedding[:,0], embedding[:,1], \n",
    "            meta_to_tsne.loc[:,'[Fe/H]_J95'].values,\n",
    "            disc=False, c_label='[Fe/H]_J95')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys2 = ['abs_Gmag', 'teff_val', 'Period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_ = dataset.meta.dropna(subset=phys2)\n",
    "if len(mu) > 30000:\n",
    "    mu_ = mu.loc[meta_.index].values[:,:-1]\n",
    "    std_ = std.loc[meta_.index].values[:,:-1]\n",
    "else:\n",
    "    mu_ = mu.iloc[:, :-1].values\n",
    "    std_ = std.iloc[:, :-1].values\n",
    "mu_ = mu_.astype(np.float64)\n",
    "std_ = std_.astype(np.float64)\n",
    "meta_.shape, mu_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_idx = meta_.reset_index().drop_duplicates(subset=['OGLE_id']).index\n",
    "meta_u = meta_.iloc[unique_idx]\n",
    "mu_u = mu_[unique_idx]\n",
    "std_u = std_[unique_idx]\n",
    "meta_u.shape, mu_u.shape, std_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta__ = meta_.copy()\n",
    "mu__ = mu_.copy()\n",
    "std__ = std_.copy()\n",
    "\n",
    "meta_ = meta_u.copy()\n",
    "mu_ = mu_u.copy()\n",
    "std_ = std_u.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = {'LinearR': LinearRegression,\n",
    "              'RFR': RandomForestRegressor,\n",
    "              'MLPR': MLPRegressor}\n",
    "\n",
    "config_dict = dict(LinearR=dict(fit_intercept=False),\n",
    "                   RFR=dict(n_estimators=100,\n",
    "                            criterion='mse',\n",
    "                            max_depth=None,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            max_features=len(phys2),\n",
    "                            n_jobs=-1),\n",
    "                  MLPR=dict(hidden_layer_sizes=(50),\n",
    "                            activation='tanh',\n",
    "                            solver='adam',\n",
    "                            alpha=0.0001,\n",
    "                            batch_size='auto',\n",
    "                            learning_rate='constant',\n",
    "                            learning_rate_init=0.001,\n",
    "                            power_t=0.5,\n",
    "                            max_iter=200,\n",
    "                            shuffle=True,\n",
    "                            early_stopping=False,\n",
    "                            validation_fraction=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_.loc[:, phys2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts_seq(lcs, cls):\n",
    "    n_cols = lcs.shape[0]\n",
    "    \n",
    "    plt.close()\n",
    "    fig, axis = plt.subplots(nrows=1, ncols=n_cols, \n",
    "                             figsize=(30,3),\n",
    "                             sharex=False, sharey=True)\n",
    "    \n",
    "    for i, ax in enumerate(axis.flat):\n",
    "        ax.plot(lcs[i, :, 0],\n",
    "                lcs[i, :, 1],\n",
    "                'k.', \n",
    "                alpha=.5, label=cls[i])\n",
    "        if cls[0] != '':\n",
    "            ax.legend(loc='lower left')\n",
    "    \n",
    "        ax.set_xlabel('Phase', fontsize=20)\n",
    "    axis[0].set_ylabel('Normalized Magnitude', fontsize=20)\n",
    "\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "    axis[0].invert_yaxis()\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig('%s/imgs/recon_lc_examples_%s.pdf' % \n",
    "    #            (path, ID), format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch_lcs_axis(model, N=100, label='RRLYR'):\n",
    "    ## phys_parms should be in this order: 'abs_Gmag', 'teff_val', 'Period'\n",
    "\n",
    "    labels = [label]*N\n",
    "    pp_vec = np.zeros((N,3), dtype=np.float32)\n",
    "    ## abs G mag\n",
    "    pp_vec[:,0] = [-0.24]*N #np.linspace(-6, -2, N, dtype=np.float32)\n",
    "    ## temp\n",
    "    pp_vec[:,1] = np.linspace(6000, 7500, N, dtype=np.float32)\n",
    "    ## period\n",
    "    pp_vec[:,2] = [0.45]*N #np.linspace(30, 1.2, N, dtype=np.float32)\n",
    "    dt = np.array([np.linspace(0,1,600, dtype=np.float32)]*N)\n",
    "    \n",
    "    latent_code = torch.from_numpy(model.predict(pp_vec).astype(np.float32))   \n",
    "    new_onehot = torch.from_numpy(dataset.label_onehot_enc.transform(np.array(labels).reshape(-1,1)))\n",
    "    dt_ = torch.from_numpy(dt)\n",
    "    \n",
    "    lchat = vae.decoder(latent_code, dt_, label=new_onehot)\n",
    "    lcs_gen = torch.cat([dt_.unsqueeze(-1), lchat], dim=-1)\n",
    "    \n",
    "    return lcs_gen.detach().numpy(), labels, pp_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'abs_Gmag', 'teff_val', 'Period'\n",
    "p = meta_.loc[:,phys2].values\n",
    "z = mu_.copy()\n",
    "\n",
    "all_lcs = []\n",
    "\n",
    "for name, reg in regressors.items():\n",
    "    if name == 'GPR': continue\n",
    "    print(name)\n",
    "    \n",
    "    model = reg(**config_dict[name])\n",
    "    try:\n",
    "        model.fit(p, z)\n",
    "    except MemoryError:\n",
    "        print('Fail')\n",
    "        continue\n",
    "    mse = metrics.mean_squared_error(z, model.predict(p))\n",
    "    print('mse  : ', mse)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    lcs_gen, labels, pp = gen_batch_lcs_axis(model, N=5, label='RRLYR')\n",
    "    all_lcs.append(lcs_gen)\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "    print(elapsed.total_seconds(), \"s\") \n",
    "    \n",
    "    #plot_ts_seq(lcs_gen, labels)\n",
    "    \n",
    "    print('______________________________')\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_names = list(regressors.keys())\n",
    "\n",
    "plt.close()\n",
    "fig, axis = plt.subplots(nrows=len(regressors), ncols=5, \n",
    "                         figsize=(30,3*len(regressors)),\n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "for i in range(len(regressors)):\n",
    "    for j in range(5):\n",
    "        axis[i, j].plot(all_lcs[i][j, :, 0],\n",
    "                        all_lcs[i][j, :, 1],\n",
    "                       'k.', \n",
    "                      alpha=.5, label=labels[j])\n",
    "        axis[0, j].text(0.40,0.12, r'$T_{eff} = %.0f K$' % (pp[j,1]), fontsize=15)\n",
    "    axis[i, 0].legend(loc='lower left')\n",
    "    axis[i, 0].text(0.05,0.22, regr_names[i], fontsize=18)\n",
    "    \n",
    "    \n",
    "axis[-1,2].set_xlabel('Phase', fontsize=20)\n",
    "axis[1,0].set_ylabel('Normalized Magnitude', fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "axis[0,0].invert_yaxis()\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig('%s/paper_figures/lc_examples_%s_%s_temp.pdf' % \n",
    "               (path, ID, labels[0]), format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_names = list(regressors.keys())\n",
    "\n",
    "plt.close()\n",
    "fig, axis = plt.subplots(nrows=len(regressors), ncols=1, \n",
    "                         figsize=(5,3*len(regressors)),\n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "for i in range(len(regressors)):\n",
    "    for j in range(5):\n",
    "        axis[i,].plot(all_lcs[i][j, :, 0],\n",
    "                        all_lcs[i][j, :, 1], \n",
    "                      alpha=.5, label=labels[j])\n",
    "    #axis[i,].legend(loc='lower left')\n",
    "    axis[i,].text(0.05,0.2, regr_names[i], fontsize=18)\n",
    "    \n",
    "    \n",
    "axis[-1].set_xlabel('Phase', fontsize=20)\n",
    "axis[1].set_ylabel('Normalized Magnitude', fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "axis[0].invert_yaxis()\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig('%s/paper_figures/lc_examples_%s_%s_temp.pdf' % \n",
    "               (path, ID, labels[0]), format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_.shape, mu_.shape, std_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys2 = ['abs_Gmag', 'teff_val', 'Period', 'dummy']\n",
    "z_aug = []\n",
    "meta_aug = []\n",
    "aug_factor = 10\n",
    "with tqdm_notebook(total=len(meta_)) as pbar:\n",
    "    for i in range(meta_.shape[0]):\n",
    "        p_aux = pd.concat([meta_.iloc[i]]*aug_factor, axis=1).T\n",
    "        p_aux.loc[:,'dummy'] = np.random.uniform(size=aug_factor)\n",
    "        meta_aug.append(p_aux)\n",
    "        \n",
    "        z_aux = np.random.normal(loc=mu_[i], scale=std_[i], \n",
    "                                 size=[aug_factor, mu_.shape[1]])\n",
    "        z_aug.append(z_aux)\n",
    "        pbar.update()\n",
    "    \n",
    "z_aug = np.concatenate(z_aug, axis=0)\n",
    "meta_aug = pd.concat(meta_aug, axis=0)\n",
    "p_aug = meta_aug.loc[:,phys2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_aug.shape, z_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, reg in regressors.items():\n",
    "    if name == 'GPR': continue\n",
    "    print(name)\n",
    "    \n",
    "    model = reg(**config_dict[name])\n",
    "    model.fit(p_aug, z_aug)\n",
    "    mse = metrics.mean_squared_error(z_aug, model.predict(p_aug))\n",
    "    print('mse  : ', mse)\n",
    "    \n",
    "    print('______________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,1,10).reshape(10,1).shape, np.random.uniform(size=(10,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch_lcs_same_phy(model, N=100, label='RRLYR', pp=[-.24, 6500, 0.42]):\n",
    "\n",
    "    labels = [label]*N\n",
    "    \n",
    "    pp_vec = np.array([pp for i in range(N)])\n",
    "    pp_dummy = np.hstack([pp_vec, np.random.uniform(size=(N,1))])\n",
    "    dt = np.array([np.linspace(0,1,600, dtype=np.float32)]*N)\n",
    "    \n",
    "    print(model.predict(pp_dummy))\n",
    "    \n",
    "    latent_code = torch.from_numpy(model.predict(pp_dummy).astype(np.float32))   \n",
    "    new_onehot = torch.from_numpy(dataset.label_onehot_enc.transform(np.array(labels).reshape(-1,1)))\n",
    "    dt_ = torch.from_numpy(dt)\n",
    "    \n",
    "    lchat = vae.decoder(latent_code, dt_, label=new_onehot)\n",
    "    lcs_gen = torch.cat([dt_.unsqueeze(-1), lchat], dim=-1)\n",
    "    \n",
    "    return lcs_gen.detach().numpy(), labels, pp_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_aug.shape, z_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'abs_Gmag', 'teff_val', 'Period'\n",
    "all_lcs = []\n",
    "\n",
    "for name, reg in regressors.items():\n",
    "    if name == 'GPR': continue\n",
    "    print(name)\n",
    "    \n",
    "    model = reg(**config_dict[name])\n",
    "    try:\n",
    "        model.fit(p_aug, z_aug)\n",
    "    except MemoryError:\n",
    "        print('Fail')\n",
    "        continue\n",
    "    mse = metrics.mean_squared_error(z_aug, model.predict(p_aug))\n",
    "    print('mse  : ', mse)\n",
    "    \n",
    "    lcs_gen, labels, pp = gen_batch_lcs_same_phy(model, N=5, label='RRLYR')\n",
    "    all_lcs.append(lcs_gen)\n",
    "    \n",
    "    plot_ts_seq(lcs_gen, labels)\n",
    "    \n",
    "    print('______________________________')\n",
    "    #break\n",
    "    \n",
    "\n",
    "# some code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_names = list(regressors.keys())\n",
    "\n",
    "plt.close()\n",
    "fig, axis = plt.subplots(nrows=len(regressors), ncols=1, \n",
    "                         figsize=(5,3*len(regressors)),\n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "for i in range(len(regressors)):\n",
    "    for j in range(5):\n",
    "        axis[i,].plot(all_lcs[i][j, :, 0],\n",
    "                        all_lcs[i][j, :, 1], \n",
    "                      alpha=.5, label=labels[j])\n",
    "    #axis[i,].legend(loc='lower left')\n",
    "    axis[i,].text(0.05,0.2, regr_names[i], fontsize=18)\n",
    "    \n",
    "    \n",
    "axis[-1].set_xlabel('Phase', fontsize=20)\n",
    "axis[1].set_ylabel('Normalized Magnitude', fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "axis[0].invert_yaxis()\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig('%s/paper_figures/lc_examples_%s_%s_temp.pdf' % \n",
    "               (path, ID, labels[0]), format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
